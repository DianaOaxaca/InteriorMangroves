{"title":"Preprocessing","markdown":{"yaml":{"title":"Preprocessing"},"headingText":"Workspace","containsRefs":false,"markdown":"\n\nPrior to conducting analyses that will elucidate the microbial dynamics associated with the mangroves under study, it is necessary to process the amplicon sequencing data. The following workflow was employed to achieve this purpose.\n\nFirst, the workspace was prepared:\n\n::: callout-tip\n\n`Directory` structure and content information\n\n`data/` Directory with raw sequences and symbolic links of sequences.\n\n`src/` Scripts directory to perform each analysis\n\n`results/` Contains results of each analysis.\n\n`outs/` Contains the output reports of each analysis.\n:::\n\nOnce the directories were prepared, the following steps were executed:\n\n## 01. Remove adapters\n\n``` bash\n#Remove primers\n\nmkdir -p results/02.cutadapt\nout=\"results/02.cutadapt\"\nFASTQ=$(ls data/*.gz | sed 's/_.*//' | sed 's/data\\///' | sort -u)\n\ndate\n\nfor FILE in ${FASTQ[@]}; do\n    echo -e \"Run cutadapt to $FILE sample\"\n        CUTADAPT='cutadapt -m 200 --pair-filter any --no-indels -g CCTACGGGNGGCWGCAG -G GACTACHVGGGTATCTAATCC -Z -j 80 -o '$out'/'$FILE'_1.fastq.gz -p '$out'/'$FILE'_2.fastq.gz data/'$FILE'_R1.fastq.gz  data/'$FILE'_R2.fastq.gz'\n        echo -e $CUTADAPT \"\\n\"\n        $CUTADAPT\ndone\n```\n\n## 02. Get ASVs with DADA2\n\n``` r\n# Get path info\ngetwd()\n\n# Load packages\nlibrary(Rcpp)\nlibrary(dada2)\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n##### 01. Prepare files -------------------------------------------------------\n\n#Load trim fastq files and list fastq_path content\nfastq_path <- \"/axolote/diana/manglares/v0.2/results/02.cutadapt\"\nlist.files(fastq_path) \n\n#Sort file names\nFs <- sort(list.files(fastq_path, pattern=\"_1.fastq\"))\nRs <- sort(list.files(fastq_path, pattern=\"_2.fastq\"))\n\n# Extract sample names\nsampleNames <- sapply(strsplit(Fs, \"_1\"), `[`, 1)\nsampleNames\n\n# Add complete path to remove ambiguities errors\nFs <- file.path(fastq_path, Fs)\nRs <- file.path(fastq_path, Rs)\n\n##### 02. Check Quality --------------------------------------------------------\n\n# Quality check plot with only the first fastq file\nQC_F1_15 <- plotQualityProfile(Fs[1:15], aggregate = TRUE)\nQC_R1_15 <- plotQualityProfile(Rs[1:15], aggregate = TRUE)\nQCsFR1_15 <- grid.arrange(QC_F1_15, QC_R1_15, nrow = 1)\n\n#save in png format\nggsave(\"results/plots/01.QualityProfile_1-15.png\", QCsFR1_15, width = 7, height = 3)\n\n#save in pdf format\nQCsFR1_15 <- grid.arrange(QC_F1_15, QC_R1_15, nrow = 1)\nggsave(\"results/plots/01.QualityProfile_1-15.pdf\", QCsFR1_15, width = 7, height = 3)\n\n##### 03.Quality control -------------------------------------------------------\n\n# Create directory for clean reads\nfilt_path <- file.path(\"results/03.Dada2\" , \"01.filter_reads\") \nif(!file_test(\"-d\", filt_path)) \n  dir.create(filt_path)\nfiltFs <- file.path(filt_path, paste0(sampleNames, \"_F_filt.fastq.gz\"))\nfiltRs <- file.path(filt_path, paste0(sampleNames, \"_R_filt.fastq.gz\"))\n\n# Filter versions\n\n# V1 \nout1 <- filterAndTrim(Fs, filtFs, Rs, filtRs,\n                      truncLen=c(250,200),\n                      maxN=0, maxEE=c(5,5), truncQ=2, rm.phix=TRUE,\n                      compress=TRUE, multithread=TRUE) \nhead(out1)\n\n#V2 extra permissive\nout2 <- filterAndTrim(Fs, filtFs, Rs, filtRs,\n                      maxN=0, maxEE=c(5,5), truncQ=2, rm.phix=TRUE,\n                      compress=TRUE, multithread=TRUE) \nhead(out2)\n\n#V3\nout3 <- filterAndTrim(Fs, filtFs, Rs, filtRs,\n                      truncLen=c(280,200),\n                      maxN=0, maxEE=c(5,5), truncQ=2, rm.phix=TRUE,\n                      compress=TRUE, multithread=TRUE) \nhead(out3)\n\n##v4\nout4 <- filterAndTrim(Fs, filtFs, Rs, filtRs,\n                      truncLen=c(0,200),\n                      maxN=0, maxEE=c(5,5), truncQ=2, rm.phix=TRUE,\n                      compress=TRUE, multithread=TRUE) \nhead(out4)\n\n##v5\nout5 <- filterAndTrim(Fs, filtFs, Rs, filtRs,\n                      truncLen=c(260,200),\n                      maxN=0, maxEE=c(5,5), truncQ=2, rm.phix=TRUE,\n                      compress=TRUE, multithread=TRUE)\nhead(out5)\n\n## compare trunc versions\nv1 <- as.data.frame(out1)\nv2 <- as.data.frame(out2)\nv3 <- as.data.frame(out3)\nv4 <- as.data.frame(out4)\nv5 <- as.data.frame(out5)\n\n\n# Percentage function\ncalculate_percentage <- function(df, group_name) {\n  df$percentage <- (df$reads.out / df$reads.in) * 100\n  df$version <- group_name\n  return(df)\n}\n\n# Get percentage\nout1_with_percentage <- calculate_percentage(v1, 'v1:250-200')\nout2_with_percentage <- calculate_percentage(v2, 'v2:0-0')\nout3_with_percentage <- calculate_percentage(v3, 'v3:280-200')\nout4_with_percentage <- calculate_percentage(v4, 'v4:0-200')\nout5_with_percentage <- calculate_percentage(v5, 'v5:260-200')\n\n# Combine percentage versions\ncombined_data <- rbind(out1_with_percentage, out2_with_percentage, \n                       out3_with_percentage, out4_with_percentage,\n                       out5_with_percentage)\n\n# Compare plot\nboxplot_versions <- ggplot(combined_data, aes(x = version, y = percentage, \n                    fill = version)) + geom_boxplot() + theme_bw() +\n  labs(x = \"Filter version\", y = \"Percentage of reads after filter\") +\n  scale_fill_brewer(palette = \"Set2\")\n\nboxplot_versions\n\n#save plot as png\nggsave(\"results/plots/02.boxplot_trunc_versions.png\", boxplot_versions, width = 6)\n\n#save plot as pdf\nggsave(\"results/plots/02.boxplot_trunc_versions.pdf\", boxplot_versions, width = 6)\n\n#Save info of final version\n#We chose v5 \nwrite.table(out5_with_percentage, file=\"results/03.Dada2/Dada_clean_reads.tsv\", quote=F, sep=\"\\t\",col.names=NA) # Table with the totals before and after cleaning\n\n##### 04.Error Model -----------------------------------------------------------\n\n#De-replicate to reduce redundance \n\nderepFs <- derepFastq(filtFs, verbose=TRUE)\nderepRs <- derepFastq(filtRs, verbose=TRUE)\n\n# Add names to de-rep object\nnames(derepFs) <- sampleNames\nnames(derepRs) <- sampleNames\n\n#Generate Error model IMPORTANT\nerrF <- learnErrors(derepFs, multithread=TRUE, verbose = TRUE)\nerrR <- learnErrors(derepRs, multithread=TRUE, verbose=TRUE)\n\nsave.image(file = \"src/Dada2.RData\") # Save point to stop for now\n\n##### 0.5 Get ASVs -------------------------------------------------------------\n# ASVs inference\ndadaFs <- dada(derepFs, err=errF, multithread=TRUE, pool = \"pseudo\", verbose=TRUE)\ndadaRs <- dada(derepRs, err=errR, multithread=TRUE, pool = \"pseudo\", verbose = TRUE)\n\nsave.image(file = \"src/Dada2.RData\") # Save point to stop for now\n\n# Merge pairs\nmergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, minOverlap = 8, verbose=TRUE)\n\n# Create ASVs table \nseqtabAll <- makeSequenceTable(mergers)\ntable(nchar(getSequences(seqtabAll)))\n\n# Remove chimeras\nseqtab_nochim <- removeBimeraDenovo(seqtabAll, method=\"consensus\", multithread=TRUE, verbose=TRUE)\n\ndim(seqtab_nochim)\nsum(seqtab_nochim)/sum(seqtabAll)\n\n##### 0.6 info -----------------------------------------------------------------\n\n# create a new table with each ASV number and its representative sequence\nPE.table_tsv_output <- seqtab_nochim\nPE.table_tsv_output[PE.table_tsv_output==1]=0 # Don't consider those values that have a single observation per sample, make them 0 (sample singletons)\nPE.table_tsv_output <- PE.table_tsv_output[,colSums(PE.table_tsv_output)>1] # filter singleton ASVs across the table\n\n# Export sequences as in fasta format\nuniquesToFasta(PE.table_tsv_output, fout=\"results/03.Dada2/ASVs.fasta\", ids=paste(\"ASV_\",1:ncol(PE.table_tsv_output), sep=\"\"))\nnochim=PE.table_tsv_output\nwrite.table(cbind(\"ASVs\"=1:nrow(t(PE.table_tsv_output)),\"rep_seq\"=rownames(t(PE.table_tsv_output))), file=\"results/03.Dada2/ASV_to_seqs-nochim.tsv\", quote=F, sep=\"\\t\",row.names=FALSE)\n\n# replace the rep_seq with an incremental ASV number\nPE.table_tsv_output <- t(PE.table_tsv_output)\nrownames(PE.table_tsv_output) <- paste0(\"ASV_\",1:nrow(PE.table_tsv_output))\n\n# and print the output ASV table\nwrite.table(PE.table_tsv_output, file=\"results/03.Dada2/ASV_to_seqs-nochim.tsv\", quote=F, sep=\"\\t\",col.names=NA)\n\n# evaluate the total table dimensions\ndim(nochim)\n\ntable(nchar(getSequences(nochim))) \n\n###Track reads lost per step ###\n\n# By using this, we can create a function to automate this for all samples in a set:\ngetN <- function(x) sum(getUniques(x)) # Where getUniques gets non-repeated sequences from a dada2 object or merger object (joined reads)\ntrack <- cbind(out1, sapply(derepFs, getN), sapply(dadaFs, getN), sapply(dadaRs, getN), rowSums(seqtabAll), rowSums(nochim))\ncolnames(track) <- c(\"Raw\", \"Qual_filter\", \"Derep\", \"ASVs R1\", \"ASVs R2\", \"Merged\", \"nonchim\")\nrownames(track) <- sampleNames\nwrite.table(track, \"results/03.Dada2/Seqs_lost_in_ASVs_processing.tsv\", col.names=NA, sep=\"\\t\")\n\n\n# Create a quick assesment of sequences lost throughout the process\npng(\"results/plots/03.preview_reads_passing_ASV_processing.png\")\n# And same thing for the percentage remaining\nmatplot(t(track[,-5]/track[,1]*100),type='l',xaxt='n', main=\"Sequences remaining after each step  - R1 (%)\", xlab=\"Step\", ylab=\" Percentage of Sequences remaining\")\naxis(1,at=1:ncol(track[,-5]),labels=colnames(track[,-5]))\n# R2\nmatplot(t(track[,-4]/track[,1]*100),type='l',xaxt='n', main=\"Sequences remaining after each step  - R2 (%)\", xlab=\"Step\", ylab=\" Percentage of Sequences remaining\")\naxis(1,at=1:ncol(track[,-4]),labels=colnames(track[,-4]))\ndev.off()\n\n##Add final table\ntrack2 <- data.frame(track)\ntrack2$percentage_used <-(track2$nonchim / track2$Raw) * 100\ntrack2\nwrite.table(track2, \"results/03.Dada2/Seqs_lost_in_ASVs_processing_percentage.tsv\", col.names=NA, sep=\"\\t\")\n\n# Save work so far\nsave.image(file = \"src/Dada2.RData\") \n```\n\n## 03. Import to QIIME2\n\n``` bash\n#!/usr/bin/bash\n## DianaOaxaca\n## Import data to QIIME2\n\n#Run in qiime conda environment\n#conda activate qiime2-2023.5\n\n#import rep seqs\nqiime tools import --input-path results/03.Dada2/ASVs.fasta --type 'FeatureData[Sequence]' --output-path results/04.qiime/ASV_rep_seq.qza\n\n# append missing header to the table for import\ncat <(echo -n \"#OTU Table\") results/03.Dada2/ASV_to_seqs-nochim.tsv > temp.txt\n\n# convert to biom\nbiom convert -i temp.txt -o temp.biom --table-type=\"OTU table\" --to-hdf5\n\n# and create table-type qza\nqiime tools import --input-path temp.biom --type 'FeatureTable[Frequency]' --input-format BIOMV210Format --output-path results/04.qiime/ASV_table.qza\n\n# remove temporal files\nrm temp.*\n```\n\n## 04. Taxonomic assignment\n\n``` bash\n#!/usr/bin/bash\n## DianaOaxaca\n## Import data to QIIME2\n\n#Run in qiime conda environment\n#conda activate qiime2-2023.5\n\n#import rep seqs\nqiime tools import --input-path results/03.Dada2/ASVs.fasta --type 'FeatureData[Sequence]' --output-path results/04.qiime/ASV_rep_seq.qza\n\n# append missing header to the table for import\ncat <(echo -n \"#OTU Table\") results/03.Dada2/ASV_to_seqs-nochim.tsv > temp.txt\n\n# convert to biom\nbiom convert -i temp.txt -o temp.biom --table-type=\"OTU table\" --to-hdf5\n\n# and create table-type qza\nqiime tools import --input-path temp.biom --type 'FeatureTable[Frequency]' --input-format BIOMV210Format --output-path results/04.qiime/ASV_table.qza\n\n# remove temporal files\nrm temp.*\n```\n\n## 05. Filters\n\n``` bash\n#!/usr/bin/bash\n#DianaOaxaca\n#Filters\n\n#Summary of the qza table imported from R\nqiime feature-table summarize \\\n--i-table results/04.qiime/ASV_table.qza \\\n--o-visualization results/04.qiime/ASV_table.qzv\n\n#Filter by frequency\n#Here I removed all ASVs with a frequency of less than 0.1% of the mean sample depth. \n#This cut-off excludes ASVs that are likely due to MiSeq bleed-through between runs (reported by Illumina to be 0.1% of reads). \n#To calculate this cut-off I identified the mean sample depth, multiplied it by 0.001, and rounded to the nearest integer. \n#This step are describe in [this paper](https://journals.asm.org/doi/pdf/10.1128/msystems.00127-16)\n\nqiime feature-table filter-features --i-table  results/04.qiime/ASV_table.qza \\\n --p-min-samples 1 --p-min-frequency 218 --o-filtered-table results/04.qiime/ASV_table_filter_freq218.qza\n\nqiime feature-table summarize --i-table results/04.qiime/ASV_table_filter_freq218.qza \\\n --o-visualization results/04.qiime/ASV_table_filter_freq218.qzv\n\n#Filter Mitochondria, chloroplast and Eukaryota\n\nqiime taxa filter-table --i-table results/04.qiime/ASV_table_filter_freq218.qza \\\n --i-taxonomy results/04.qiime/taxonomy.qza --p-exclude Eukaryota,Mitochondria,Chloroplast \\\n --p-include p__ --o-filtered-table results/04.qiime/ASV_table_filter_freq218_emc.qza\n\nqiime feature-table summarize --i-table results/04.qiime/ASV_table_filter_freq218_emc.qza \\\n --o-visualization results/04.qiime/ASV_table_filter_freq218_emc.qzv\n\n#remove in fasta sequences\nqiime feature-table filter-seqs  --i-table results/04.qiime/ASV_table_filter_freq218_emc.qza \\\n --i-data results/04.qiime/ASV_rep_seq.qza --o-filtered-data results/04.qiime/ASV_rep_seq_filters.qza\n```\n\n## 06. Phylogeny\n\n``` bash\n#!/usr/bin/bash\n#Get iqtree phylogeny\n\ndate\necho \"Start phylogeny\"\n\nqiime phylogeny align-to-tree-mafft-iqtree \\\n --p-n-threads auto --i-sequences results/04.qiime/ASV_rep_seq_filters.qza \\\n --o-alignment results/04.qiime/align.qza \\\n --o-masked-alignment results/04.qiime/masked-align.qza \\\n --o-tree results/04.qiime/unrooted-tree-iqtree.qza \\\n --o-rooted-tree results/04.qiime/rooted-tree-iqtree.qza --verbose\n\necho \"finish phylogeny!\"\n\ndate\n```\n\n## 07. Get public data\n\n``` bash\n# Yaxche\n```\n\n::: callout-important\n## Public data preprocessing\n\nThe public data obtained for comparative purposes was preprocessed in the same way as described in the previous steps.\n:::\n\n## 08. Clustering types of mangroves for comparative analysis\n\n``` bash\n#Run in qiime conda environment\nconda activate qiime2-2023.5\n\n#Repeat with every ASV_table (Celestún, Estero Pargo and San Pedro River)\n#import rep seqs\nqiime tools import --input-path results/03.Dada2/ASVs.fasta --type 'FeatureData[Sequence]' --output-path results/04.qiime/ASV_rep_seq.qza\n\n# append missing header to the table for import\ncat <(echo -n \"#OTU Table\") results/03.Dada2/ASV_to_seqs-nochim.tsv > temp.txt\n\n# convert to biom\nbiom convert -i temp.txt -o temp.biom --table-type=\"OTU table\" --to-hdf5\n\n# and create table-type qza\nqiime tools import --input-path temp.biom --type 'FeatureTable[Frequency]' --input-format BIOMV210Format --output-path results/04.qiime/ASV_table.qza\n\n# remove temporal files\nrm temp.*\n\n#Merge of the frequency tables from distinct analysis\nqiime feature-table merge \n--i-tables ASV_table_Celestun.qza ASV_table_Estero.qza ASV_table_SanPedro.qza --p-overlap-method sum \n--o-merged-table merged-table.qza\n\n#Merge of the Representative sequences from distinct analysis \nqiime feature-table merge-seqs \n--i-data ASV_Celestun_rep_seq.qza ASV_Estero_rep_seq.qza ASV_SanPedro_rep_seq.qza \n--o-merged-data merged-rep_seqs.qza\n\n#Closed reference clustering for Meta-Analysis\nqiime vsearch cluster-features-closed-reference   \n--i-table merged-table.qza   \n--i-sequences merged-rep_seqs.qza   \n--i-reference-sequences silva-138-99-seqs.qza   \n--p-perc-identity 0.97   \n--o-clustered-table table-cr-97.qza   \n--o-clustered-sequences rep-seqs-cr-97.qza   \n--o-unmatched-sequences unmatched-cr-97.qza\n\n#Taxonomic assignment with SILVA\n qiime feature-classifier classify-sklearn   \n--i-classifier classifier_silva_138_trained.qza   \n--i-reads rep-seqs-cr-97.qza    \n--o-classification taxonomyEstero.qza \n--p-n-jobs 40\n\n#Filter by frequency\nqiime feature-table filter-features --i-table  merged_table.qza \n--p-min-samples 1 \n--p-min-frequency 218 \n--o-filtered-table clustered_table_filter_freq218.qza\n\n#Filter Mitochondria, chloroplast and Eukaryota\nqiime taxa filter-table \n--i-table Clustered_table_filter_freq218.qza \n--i-taxonomy taxonomy.qza \n--p-exclude Eukaryota,Mitochondria,Chloroplast  \n--p-include p__ \n--o-filtered-table clustered_table_filter_freq218_emcEstero.qza\n```\n","srcMarkdownNoYaml":"\n\nPrior to conducting analyses that will elucidate the microbial dynamics associated with the mangroves under study, it is necessary to process the amplicon sequencing data. The following workflow was employed to achieve this purpose.\n\nFirst, the workspace was prepared:\n\n::: callout-tip\n## Workspace\n\n`Directory` structure and content information\n\n`data/` Directory with raw sequences and symbolic links of sequences.\n\n`src/` Scripts directory to perform each analysis\n\n`results/` Contains results of each analysis.\n\n`outs/` Contains the output reports of each analysis.\n:::\n\nOnce the directories were prepared, the following steps were executed:\n\n## 01. Remove adapters\n\n``` bash\n#Remove primers\n\nmkdir -p results/02.cutadapt\nout=\"results/02.cutadapt\"\nFASTQ=$(ls data/*.gz | sed 's/_.*//' | sed 's/data\\///' | sort -u)\n\ndate\n\nfor FILE in ${FASTQ[@]}; do\n    echo -e \"Run cutadapt to $FILE sample\"\n        CUTADAPT='cutadapt -m 200 --pair-filter any --no-indels -g CCTACGGGNGGCWGCAG -G GACTACHVGGGTATCTAATCC -Z -j 80 -o '$out'/'$FILE'_1.fastq.gz -p '$out'/'$FILE'_2.fastq.gz data/'$FILE'_R1.fastq.gz  data/'$FILE'_R2.fastq.gz'\n        echo -e $CUTADAPT \"\\n\"\n        $CUTADAPT\ndone\n```\n\n## 02. Get ASVs with DADA2\n\n``` r\n# Get path info\ngetwd()\n\n# Load packages\nlibrary(Rcpp)\nlibrary(dada2)\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n##### 01. Prepare files -------------------------------------------------------\n\n#Load trim fastq files and list fastq_path content\nfastq_path <- \"/axolote/diana/manglares/v0.2/results/02.cutadapt\"\nlist.files(fastq_path) \n\n#Sort file names\nFs <- sort(list.files(fastq_path, pattern=\"_1.fastq\"))\nRs <- sort(list.files(fastq_path, pattern=\"_2.fastq\"))\n\n# Extract sample names\nsampleNames <- sapply(strsplit(Fs, \"_1\"), `[`, 1)\nsampleNames\n\n# Add complete path to remove ambiguities errors\nFs <- file.path(fastq_path, Fs)\nRs <- file.path(fastq_path, Rs)\n\n##### 02. Check Quality --------------------------------------------------------\n\n# Quality check plot with only the first fastq file\nQC_F1_15 <- plotQualityProfile(Fs[1:15], aggregate = TRUE)\nQC_R1_15 <- plotQualityProfile(Rs[1:15], aggregate = TRUE)\nQCsFR1_15 <- grid.arrange(QC_F1_15, QC_R1_15, nrow = 1)\n\n#save in png format\nggsave(\"results/plots/01.QualityProfile_1-15.png\", QCsFR1_15, width = 7, height = 3)\n\n#save in pdf format\nQCsFR1_15 <- grid.arrange(QC_F1_15, QC_R1_15, nrow = 1)\nggsave(\"results/plots/01.QualityProfile_1-15.pdf\", QCsFR1_15, width = 7, height = 3)\n\n##### 03.Quality control -------------------------------------------------------\n\n# Create directory for clean reads\nfilt_path <- file.path(\"results/03.Dada2\" , \"01.filter_reads\") \nif(!file_test(\"-d\", filt_path)) \n  dir.create(filt_path)\nfiltFs <- file.path(filt_path, paste0(sampleNames, \"_F_filt.fastq.gz\"))\nfiltRs <- file.path(filt_path, paste0(sampleNames, \"_R_filt.fastq.gz\"))\n\n# Filter versions\n\n# V1 \nout1 <- filterAndTrim(Fs, filtFs, Rs, filtRs,\n                      truncLen=c(250,200),\n                      maxN=0, maxEE=c(5,5), truncQ=2, rm.phix=TRUE,\n                      compress=TRUE, multithread=TRUE) \nhead(out1)\n\n#V2 extra permissive\nout2 <- filterAndTrim(Fs, filtFs, Rs, filtRs,\n                      maxN=0, maxEE=c(5,5), truncQ=2, rm.phix=TRUE,\n                      compress=TRUE, multithread=TRUE) \nhead(out2)\n\n#V3\nout3 <- filterAndTrim(Fs, filtFs, Rs, filtRs,\n                      truncLen=c(280,200),\n                      maxN=0, maxEE=c(5,5), truncQ=2, rm.phix=TRUE,\n                      compress=TRUE, multithread=TRUE) \nhead(out3)\n\n##v4\nout4 <- filterAndTrim(Fs, filtFs, Rs, filtRs,\n                      truncLen=c(0,200),\n                      maxN=0, maxEE=c(5,5), truncQ=2, rm.phix=TRUE,\n                      compress=TRUE, multithread=TRUE) \nhead(out4)\n\n##v5\nout5 <- filterAndTrim(Fs, filtFs, Rs, filtRs,\n                      truncLen=c(260,200),\n                      maxN=0, maxEE=c(5,5), truncQ=2, rm.phix=TRUE,\n                      compress=TRUE, multithread=TRUE)\nhead(out5)\n\n## compare trunc versions\nv1 <- as.data.frame(out1)\nv2 <- as.data.frame(out2)\nv3 <- as.data.frame(out3)\nv4 <- as.data.frame(out4)\nv5 <- as.data.frame(out5)\n\n\n# Percentage function\ncalculate_percentage <- function(df, group_name) {\n  df$percentage <- (df$reads.out / df$reads.in) * 100\n  df$version <- group_name\n  return(df)\n}\n\n# Get percentage\nout1_with_percentage <- calculate_percentage(v1, 'v1:250-200')\nout2_with_percentage <- calculate_percentage(v2, 'v2:0-0')\nout3_with_percentage <- calculate_percentage(v3, 'v3:280-200')\nout4_with_percentage <- calculate_percentage(v4, 'v4:0-200')\nout5_with_percentage <- calculate_percentage(v5, 'v5:260-200')\n\n# Combine percentage versions\ncombined_data <- rbind(out1_with_percentage, out2_with_percentage, \n                       out3_with_percentage, out4_with_percentage,\n                       out5_with_percentage)\n\n# Compare plot\nboxplot_versions <- ggplot(combined_data, aes(x = version, y = percentage, \n                    fill = version)) + geom_boxplot() + theme_bw() +\n  labs(x = \"Filter version\", y = \"Percentage of reads after filter\") +\n  scale_fill_brewer(palette = \"Set2\")\n\nboxplot_versions\n\n#save plot as png\nggsave(\"results/plots/02.boxplot_trunc_versions.png\", boxplot_versions, width = 6)\n\n#save plot as pdf\nggsave(\"results/plots/02.boxplot_trunc_versions.pdf\", boxplot_versions, width = 6)\n\n#Save info of final version\n#We chose v5 \nwrite.table(out5_with_percentage, file=\"results/03.Dada2/Dada_clean_reads.tsv\", quote=F, sep=\"\\t\",col.names=NA) # Table with the totals before and after cleaning\n\n##### 04.Error Model -----------------------------------------------------------\n\n#De-replicate to reduce redundance \n\nderepFs <- derepFastq(filtFs, verbose=TRUE)\nderepRs <- derepFastq(filtRs, verbose=TRUE)\n\n# Add names to de-rep object\nnames(derepFs) <- sampleNames\nnames(derepRs) <- sampleNames\n\n#Generate Error model IMPORTANT\nerrF <- learnErrors(derepFs, multithread=TRUE, verbose = TRUE)\nerrR <- learnErrors(derepRs, multithread=TRUE, verbose=TRUE)\n\nsave.image(file = \"src/Dada2.RData\") # Save point to stop for now\n\n##### 0.5 Get ASVs -------------------------------------------------------------\n# ASVs inference\ndadaFs <- dada(derepFs, err=errF, multithread=TRUE, pool = \"pseudo\", verbose=TRUE)\ndadaRs <- dada(derepRs, err=errR, multithread=TRUE, pool = \"pseudo\", verbose = TRUE)\n\nsave.image(file = \"src/Dada2.RData\") # Save point to stop for now\n\n# Merge pairs\nmergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, minOverlap = 8, verbose=TRUE)\n\n# Create ASVs table \nseqtabAll <- makeSequenceTable(mergers)\ntable(nchar(getSequences(seqtabAll)))\n\n# Remove chimeras\nseqtab_nochim <- removeBimeraDenovo(seqtabAll, method=\"consensus\", multithread=TRUE, verbose=TRUE)\n\ndim(seqtab_nochim)\nsum(seqtab_nochim)/sum(seqtabAll)\n\n##### 0.6 info -----------------------------------------------------------------\n\n# create a new table with each ASV number and its representative sequence\nPE.table_tsv_output <- seqtab_nochim\nPE.table_tsv_output[PE.table_tsv_output==1]=0 # Don't consider those values that have a single observation per sample, make them 0 (sample singletons)\nPE.table_tsv_output <- PE.table_tsv_output[,colSums(PE.table_tsv_output)>1] # filter singleton ASVs across the table\n\n# Export sequences as in fasta format\nuniquesToFasta(PE.table_tsv_output, fout=\"results/03.Dada2/ASVs.fasta\", ids=paste(\"ASV_\",1:ncol(PE.table_tsv_output), sep=\"\"))\nnochim=PE.table_tsv_output\nwrite.table(cbind(\"ASVs\"=1:nrow(t(PE.table_tsv_output)),\"rep_seq\"=rownames(t(PE.table_tsv_output))), file=\"results/03.Dada2/ASV_to_seqs-nochim.tsv\", quote=F, sep=\"\\t\",row.names=FALSE)\n\n# replace the rep_seq with an incremental ASV number\nPE.table_tsv_output <- t(PE.table_tsv_output)\nrownames(PE.table_tsv_output) <- paste0(\"ASV_\",1:nrow(PE.table_tsv_output))\n\n# and print the output ASV table\nwrite.table(PE.table_tsv_output, file=\"results/03.Dada2/ASV_to_seqs-nochim.tsv\", quote=F, sep=\"\\t\",col.names=NA)\n\n# evaluate the total table dimensions\ndim(nochim)\n\ntable(nchar(getSequences(nochim))) \n\n###Track reads lost per step ###\n\n# By using this, we can create a function to automate this for all samples in a set:\ngetN <- function(x) sum(getUniques(x)) # Where getUniques gets non-repeated sequences from a dada2 object or merger object (joined reads)\ntrack <- cbind(out1, sapply(derepFs, getN), sapply(dadaFs, getN), sapply(dadaRs, getN), rowSums(seqtabAll), rowSums(nochim))\ncolnames(track) <- c(\"Raw\", \"Qual_filter\", \"Derep\", \"ASVs R1\", \"ASVs R2\", \"Merged\", \"nonchim\")\nrownames(track) <- sampleNames\nwrite.table(track, \"results/03.Dada2/Seqs_lost_in_ASVs_processing.tsv\", col.names=NA, sep=\"\\t\")\n\n\n# Create a quick assesment of sequences lost throughout the process\npng(\"results/plots/03.preview_reads_passing_ASV_processing.png\")\n# And same thing for the percentage remaining\nmatplot(t(track[,-5]/track[,1]*100),type='l',xaxt='n', main=\"Sequences remaining after each step  - R1 (%)\", xlab=\"Step\", ylab=\" Percentage of Sequences remaining\")\naxis(1,at=1:ncol(track[,-5]),labels=colnames(track[,-5]))\n# R2\nmatplot(t(track[,-4]/track[,1]*100),type='l',xaxt='n', main=\"Sequences remaining after each step  - R2 (%)\", xlab=\"Step\", ylab=\" Percentage of Sequences remaining\")\naxis(1,at=1:ncol(track[,-4]),labels=colnames(track[,-4]))\ndev.off()\n\n##Add final table\ntrack2 <- data.frame(track)\ntrack2$percentage_used <-(track2$nonchim / track2$Raw) * 100\ntrack2\nwrite.table(track2, \"results/03.Dada2/Seqs_lost_in_ASVs_processing_percentage.tsv\", col.names=NA, sep=\"\\t\")\n\n# Save work so far\nsave.image(file = \"src/Dada2.RData\") \n```\n\n## 03. Import to QIIME2\n\n``` bash\n#!/usr/bin/bash\n## DianaOaxaca\n## Import data to QIIME2\n\n#Run in qiime conda environment\n#conda activate qiime2-2023.5\n\n#import rep seqs\nqiime tools import --input-path results/03.Dada2/ASVs.fasta --type 'FeatureData[Sequence]' --output-path results/04.qiime/ASV_rep_seq.qza\n\n# append missing header to the table for import\ncat <(echo -n \"#OTU Table\") results/03.Dada2/ASV_to_seqs-nochim.tsv > temp.txt\n\n# convert to biom\nbiom convert -i temp.txt -o temp.biom --table-type=\"OTU table\" --to-hdf5\n\n# and create table-type qza\nqiime tools import --input-path temp.biom --type 'FeatureTable[Frequency]' --input-format BIOMV210Format --output-path results/04.qiime/ASV_table.qza\n\n# remove temporal files\nrm temp.*\n```\n\n## 04. Taxonomic assignment\n\n``` bash\n#!/usr/bin/bash\n## DianaOaxaca\n## Import data to QIIME2\n\n#Run in qiime conda environment\n#conda activate qiime2-2023.5\n\n#import rep seqs\nqiime tools import --input-path results/03.Dada2/ASVs.fasta --type 'FeatureData[Sequence]' --output-path results/04.qiime/ASV_rep_seq.qza\n\n# append missing header to the table for import\ncat <(echo -n \"#OTU Table\") results/03.Dada2/ASV_to_seqs-nochim.tsv > temp.txt\n\n# convert to biom\nbiom convert -i temp.txt -o temp.biom --table-type=\"OTU table\" --to-hdf5\n\n# and create table-type qza\nqiime tools import --input-path temp.biom --type 'FeatureTable[Frequency]' --input-format BIOMV210Format --output-path results/04.qiime/ASV_table.qza\n\n# remove temporal files\nrm temp.*\n```\n\n## 05. Filters\n\n``` bash\n#!/usr/bin/bash\n#DianaOaxaca\n#Filters\n\n#Summary of the qza table imported from R\nqiime feature-table summarize \\\n--i-table results/04.qiime/ASV_table.qza \\\n--o-visualization results/04.qiime/ASV_table.qzv\n\n#Filter by frequency\n#Here I removed all ASVs with a frequency of less than 0.1% of the mean sample depth. \n#This cut-off excludes ASVs that are likely due to MiSeq bleed-through between runs (reported by Illumina to be 0.1% of reads). \n#To calculate this cut-off I identified the mean sample depth, multiplied it by 0.001, and rounded to the nearest integer. \n#This step are describe in [this paper](https://journals.asm.org/doi/pdf/10.1128/msystems.00127-16)\n\nqiime feature-table filter-features --i-table  results/04.qiime/ASV_table.qza \\\n --p-min-samples 1 --p-min-frequency 218 --o-filtered-table results/04.qiime/ASV_table_filter_freq218.qza\n\nqiime feature-table summarize --i-table results/04.qiime/ASV_table_filter_freq218.qza \\\n --o-visualization results/04.qiime/ASV_table_filter_freq218.qzv\n\n#Filter Mitochondria, chloroplast and Eukaryota\n\nqiime taxa filter-table --i-table results/04.qiime/ASV_table_filter_freq218.qza \\\n --i-taxonomy results/04.qiime/taxonomy.qza --p-exclude Eukaryota,Mitochondria,Chloroplast \\\n --p-include p__ --o-filtered-table results/04.qiime/ASV_table_filter_freq218_emc.qza\n\nqiime feature-table summarize --i-table results/04.qiime/ASV_table_filter_freq218_emc.qza \\\n --o-visualization results/04.qiime/ASV_table_filter_freq218_emc.qzv\n\n#remove in fasta sequences\nqiime feature-table filter-seqs  --i-table results/04.qiime/ASV_table_filter_freq218_emc.qza \\\n --i-data results/04.qiime/ASV_rep_seq.qza --o-filtered-data results/04.qiime/ASV_rep_seq_filters.qza\n```\n\n## 06. Phylogeny\n\n``` bash\n#!/usr/bin/bash\n#Get iqtree phylogeny\n\ndate\necho \"Start phylogeny\"\n\nqiime phylogeny align-to-tree-mafft-iqtree \\\n --p-n-threads auto --i-sequences results/04.qiime/ASV_rep_seq_filters.qza \\\n --o-alignment results/04.qiime/align.qza \\\n --o-masked-alignment results/04.qiime/masked-align.qza \\\n --o-tree results/04.qiime/unrooted-tree-iqtree.qza \\\n --o-rooted-tree results/04.qiime/rooted-tree-iqtree.qza --verbose\n\necho \"finish phylogeny!\"\n\ndate\n```\n\n## 07. Get public data\n\n``` bash\n# Yaxche\n```\n\n::: callout-important\n## Public data preprocessing\n\nThe public data obtained for comparative purposes was preprocessed in the same way as described in the previous steps.\n:::\n\n## 08. Clustering types of mangroves for comparative analysis\n\n``` bash\n#Run in qiime conda environment\nconda activate qiime2-2023.5\n\n#Repeat with every ASV_table (Celestún, Estero Pargo and San Pedro River)\n#import rep seqs\nqiime tools import --input-path results/03.Dada2/ASVs.fasta --type 'FeatureData[Sequence]' --output-path results/04.qiime/ASV_rep_seq.qza\n\n# append missing header to the table for import\ncat <(echo -n \"#OTU Table\") results/03.Dada2/ASV_to_seqs-nochim.tsv > temp.txt\n\n# convert to biom\nbiom convert -i temp.txt -o temp.biom --table-type=\"OTU table\" --to-hdf5\n\n# and create table-type qza\nqiime tools import --input-path temp.biom --type 'FeatureTable[Frequency]' --input-format BIOMV210Format --output-path results/04.qiime/ASV_table.qza\n\n# remove temporal files\nrm temp.*\n\n#Merge of the frequency tables from distinct analysis\nqiime feature-table merge \n--i-tables ASV_table_Celestun.qza ASV_table_Estero.qza ASV_table_SanPedro.qza --p-overlap-method sum \n--o-merged-table merged-table.qza\n\n#Merge of the Representative sequences from distinct analysis \nqiime feature-table merge-seqs \n--i-data ASV_Celestun_rep_seq.qza ASV_Estero_rep_seq.qza ASV_SanPedro_rep_seq.qza \n--o-merged-data merged-rep_seqs.qza\n\n#Closed reference clustering for Meta-Analysis\nqiime vsearch cluster-features-closed-reference   \n--i-table merged-table.qza   \n--i-sequences merged-rep_seqs.qza   \n--i-reference-sequences silva-138-99-seqs.qza   \n--p-perc-identity 0.97   \n--o-clustered-table table-cr-97.qza   \n--o-clustered-sequences rep-seqs-cr-97.qza   \n--o-unmatched-sequences unmatched-cr-97.qza\n\n#Taxonomic assignment with SILVA\n qiime feature-classifier classify-sklearn   \n--i-classifier classifier_silva_138_trained.qza   \n--i-reads rep-seqs-cr-97.qza    \n--o-classification taxonomyEstero.qza \n--p-n-jobs 40\n\n#Filter by frequency\nqiime feature-table filter-features --i-table  merged_table.qza \n--p-min-samples 1 \n--p-min-frequency 218 \n--o-filtered-table clustered_table_filter_freq218.qza\n\n#Filter Mitochondria, chloroplast and Eukaryota\nqiime taxa filter-table \n--i-table Clustered_table_filter_freq218.qza \n--i-taxonomy taxonomy.qza \n--p-exclude Eukaryota,Mitochondria,Chloroplast  \n--p-include p__ \n--o-filtered-table clustered_table_filter_freq218_emcEstero.qza\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":true,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"01.Preprocessing.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.37","editor":"visual","theme":{"light":["cosmo","theme.scss"],"dark":["cosmo","theme-dark.scss"]},"mainfont":"Atkinson Hyperlegible","code-copy":true,"anchor-sections":true,"footnotes-hover":false,"title":"Preprocessing"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}